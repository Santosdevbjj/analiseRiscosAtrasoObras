{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMDSpRKq9eQArE6mLxOlyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santosdevbjj/analiseRiscosAtrasoObras/blob/main/Notebooks/02_limpeza_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "9tdlUhQSSdav",
        "outputId": "10315399-2ffe-40ff-9c37-e7de594bb3a6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/raw/obrasccbjj.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3383741157.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Carregar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mobras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"obrasccbjj.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mforn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"fornecedoresccbjj.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mclima\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"climaccbjj.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/obrasccbjj.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================\n",
        "# Notebook 02 — Limpeza e Pré‑Processamento (ETL)\n",
        "# ============================\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "raw_path = \"data/raw/\"\n",
        "\n",
        "# Carregar\n",
        "obras = pd.read_csv(raw_path + \"obrasccbjj.csv\")\n",
        "forn = pd.read_csv(raw_path + \"fornecedoresccbjj.csv\")\n",
        "clima = pd.read_csv(raw_path + \"climaccbjj.csv\")\n",
        "mao = pd.read_csv(raw_path + \"mao_obraccbjj.csv\")\n",
        "ativ = pd.read_csv(raw_path + \"atividadesccbjj.csv\")\n",
        "supr = pd.read_csv(raw_path + \"suprimentosccbjj.csv\")\n",
        "bot = pd.read_csv(raw_path + \"base_consulta_botccbjj.csv\")\n",
        "rel = pd.read_csv(raw_path + \"relatorio_consolidadoccbjj.csv\")\n",
        "\n",
        "# Padronização de texto\n",
        "for df in [obras, clima, mao, ativ, supr, bot, rel]:\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == object:\n",
        "            df[col] = df[col].astype(str).str.strip()\n",
        "\n",
        "# Tipos corretos\n",
        "obras[\"data_inicio_prevista\"] = pd.to_datetime(obras[\"data_inicio_prevista\"], errors=\"coerce\")\n",
        "num_cols_obras = [\"orcamento_estimado\",\"prazo_previsto_dias\",\"prazo_real_dias\",\"chuva_mm\",\"Atrasou\"]\n",
        "for c in num_cols_obras:\n",
        "    obras[c] = pd.to_numeric(obras[c], errors=\"coerce\")\n",
        "\n",
        "# Nulos: medianas\n",
        "for c in [\"prazo_previsto_dias\",\"prazo_real_dias\",\"chuva_mm\",\"orcamento_estimado\"]:\n",
        "    obras[c] = obras[c].fillna(obras[c].median())\n",
        "\n",
        "# Definir target\n",
        "obras[\"atraso_dias\"] = obras[\"prazo_real_dias\"] - obras[\"prazo_previsto_dias\"]\n",
        "obras[\"atraso_flag\"] = (obras[\"atraso_dias\"] > 0).astype(int)\n",
        "\n",
        "# Agregações de atividades\n",
        "agg_ativ = ativ.groupby(\"id_obra\").agg({\n",
        "    \"dias_atraso\": \"sum\",\n",
        "    \"id_atividade\": \"count\"\n",
        "}).rename(columns={\"dias_atraso\":\"dias_atraso_total\",\"id_atividade\":\"qtd_atividades\"}).reset_index()\n",
        "\n",
        "# Taxas de insucesso\n",
        "taxa_obra = supr.groupby(\"id_obra\")[\"atrasou_entrega\"].mean().rename(\"taxa_insucesso_obra\").reset_index()\n",
        "\n",
        "# Merge principal\n",
        "merged = obras.rename(columns={\"Id_obra\":\"id_obra\"}) \\\n",
        "    .merge(clima, on=\"id_obra\", how=\"left\") \\\n",
        "    .merge(mao.rename(columns={\"Id_obra\":\"id_obra\"}), on=\"id_obra\", how=\"left\") \\\n",
        "    .merge(agg_ativ, on=\"id_obra\", how=\"left\") \\\n",
        "    .merge(taxa_obra, on=\"id_obra\", how=\"left\") \\\n",
        "    .merge(bot[[\"id_obra\",\"complexidade_obra\",\"risco_etapa\",\"nivel_chuva\",\"tipo_solo\",\"material\"]], on=\"id_obra\", how=\"left\") \\\n",
        "    .merge(rel[[\"id_obra\",\"risco_medio\",\"pior_etapa\",\"risco_pior\",\"material_critico\",\"taxa_insucesso\"]], on=\"id_obra\", how=\"left\")\n",
        "\n",
        "# Limpeza de nulos numéricos\n",
        "num_cols = [\"prazo_previsto_dias\",\"prazo_real_dias\",\"chuva_mm\",\"orcamento_estimado\",\"qtd_engenheiros\",\n",
        "            \"qtd_pedreiros\",\"qtd_servente_pedreiros\",\"dias_atraso_total\",\"qtd_atividades\",\"taxa_insucesso_obra\",\n",
        "            \"complexidade_obra\",\"risco_etapa\",\"nivel_chuva\",\"risco_medio\",\"risco_pior\",\"taxa_insucesso\",\"atraso_dias\"]\n",
        "for c in num_cols:\n",
        "    if c in merged.columns:\n",
        "        merged[c] = pd.to_numeric(merged[c], errors=\"coerce\").fillna(merged[c].median())\n",
        "\n",
        "# Padronizar categóricas\n",
        "for c in [\"cidade\",\"tipo_solo\",\"material\",\"pior_etapa\",\"material_critico\"]:\n",
        "    if c in merged.columns:\n",
        "        merged[c] = merged[c].astype(str).str.strip().str.title()\n",
        "\n",
        "# Features derivadas\n",
        "merged[\"atraso_pct\"] = merged[\"atraso_dias\"] / merged[\"prazo_previsto_dias\"].replace(0, np.nan)\n",
        "merged[\"engenheiros_ratio\"] = merged[\"qtd_engenheiros\"] / merged[\"qtd_pedreiros\"].replace(0, np.nan)\n",
        "merged[\"produtividade_pedreiro\"] = merged[\"prazo_previsto_dias\"] / merged[\"qtd_pedreiros\"].replace(0, np.nan)\n",
        "merged[\"chuva_intensa_flag\"] = (merged[\"chuva_mm\"] >= 200).astype(int)\n",
        "\n",
        "# Salvar dataset final\n",
        "os.makedirs(\"data/processed\", exist_ok=True)\n",
        "out_file = \"data/processed/dataset_modelo.csv\"\n",
        "merged.to_csv(out_file, index=False)\n",
        "print(f\"✅ Dataset final salvo: {out_file}\")\n",
        "\n",
        "# Download automático no Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(out_file)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Prévia\n",
        "print(merged[[\"id_obra\",\"cidade\",\"prazo_previsto_dias\",\"prazo_real_dias\",\"atraso_flag\"]].head())"
      ]
    }
  ]
}