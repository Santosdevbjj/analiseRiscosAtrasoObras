{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpc6SQVq5K9gbVbKIVpteT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santosdevbjj/analiseRiscosAtrasoObras/blob/main/Notebooks/02_modelagem_preditiva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "0bOJ2jElwOPo",
        "outputId": "52265aee-e21c-42ec-fbaf-9a1970526436"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/raw/atividades.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3183157837.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 3. Carregamento dos CSVs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0matividades\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/raw/atividades.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mfornecedores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/raw/fornecedores.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mobras\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/raw/obras.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/atividades.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================\n",
        "# 1. Clonar o reposit√≥rio e acessar a pasta\n",
        "# ============================================================\n",
        "# !git clone https://github.com/Santosdevbjj/analiseRiscosAtrasoObras.git\n",
        "# %cd analiseRiscosAtrasoObras\n",
        "\n",
        "# ============================================================\n",
        "# 2. Imports\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# 3. Carregamento dos CSVs\n",
        "# ============================================================\n",
        "atividades   = pd.read_csv(\"data/raw/atividades.csv\")\n",
        "fornecedores = pd.read_csv(\"data/raw/fornecedores.csv\")\n",
        "obras        = pd.read_csv(\"data/raw/obras.csv\")\n",
        "suprimentos  = pd.read_csv(\"data/raw/suprimentos.csv\")\n",
        "\n",
        "# Visualizar as primeiras linhas de cada dataset\n",
        "print(\"Atividades:\")\n",
        "print(atividades.head(), \"\\n\")\n",
        "\n",
        "print(\"Fornecedores:\")\n",
        "print(fornecedores.head(), \"\\n\")\n",
        "\n",
        "print(\"Obras:\")\n",
        "print(obras.head(), \"\\n\")\n",
        "\n",
        "print(\"Suprimentos:\")\n",
        "print(suprimentos.head(), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 1. Imports e Setup\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "JKzyRmiKwm-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 2. Carregamento dos Dados\n",
        "# ============================================================\n",
        "atividades   = pd.read_csv(\"data/raw/atividades.csv\")\n",
        "fornecedores = pd.read_csv(\"data/raw/fornecedores.csv\")\n",
        "obras        = pd.read_csv(\"data/raw/obras.csv\")\n",
        "suprimentos  = pd.read_csv(\"data/raw/suprimentos.csv\")\n",
        "\n",
        "print(\"Datasets carregados:\")\n",
        "print(\"atividades:\", atividades.shape)\n",
        "print(\"fornecedores:\", fornecedores.shape)\n",
        "print(\"obras:\", obras.shape)\n",
        "print(\"suprimentos:\", suprimentos.shape)"
      ],
      "metadata": {
        "id": "OCZnTzzu5-Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 3. Integra√ß√£o dos Dados\n",
        "# ============================================================\n",
        "# 1. atividades + obras\n",
        "df_mestre = atividades.merge(obras, on=\"id_obra\", how=\"left\")\n",
        "\n",
        "# 2. adiciona suprimentos (traz id_fornecedor)\n",
        "df_mestre = df_mestre.merge(suprimentos, on=[\"id_obra\", \"id_atividade\"], how=\"left\")\n",
        "\n",
        "# 3. adiciona fornecedores\n",
        "df_mestre = df_mestre.merge(fornecedores, on=\"id_fornecedor\", how=\"left\")\n",
        "\n",
        "print(\"df_mestre consolidado:\")\n",
        "print(df_mestre.head())\n",
        "print(\"Shape:\", df_mestre.shape)"
      ],
      "metadata": {
        "id": "ensizyRJ6Ekx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 4. Limpeza b√°sica\n",
        "# ============================================================\n",
        "df_mestre = df_mestre.dropna(subset=[\"dias_atraso\"]).copy()\n",
        "df_mestre[\"rating_confiabilidade\"] = df_mestre[\"rating_confiabilidade\"].fillna(df_mestre[\"rating_confiabilidade\"].median())\n",
        "df_mestre[\"orcamento_estimado\"] = df_mestre[\"orcamento_estimado\"].clip(lower=0).fillna(df_mestre[\"orcamento_estimado\"].median())\n",
        "\n",
        "for col in [\"material\", \"cidade\", \"etapa\"]:\n",
        "    df_mestre[col] = df_mestre[col].fillna(\"desconhecido\")"
      ],
      "metadata": {
        "id": "WWY0RyYK6L3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 5. Feature Engineering\n",
        "# ============================================================\n",
        "df_mestre = df_mestre.assign(\n",
        "    taxa_insucesso_fornecedor = df_mestre.groupby(\"id_fornecedor\")[\"dias_atraso\"].transform(lambda x: (x > 0).mean()),\n",
        "    complexidade_obra = np.log1p(df_mestre[\"orcamento_estimado\"]),\n",
        "    risco_etapa = df_mestre.groupby(\"etapa\")[\"dias_atraso\"].transform(\"mean\")\n",
        ")\n",
        "\n",
        "print(\"Preview de features derivadas:\")\n",
        "print(df_mestre[[\n",
        "    \"id_obra\",\"id_fornecedor\",\"etapa\",\"dias_atraso\",\n",
        "    \"taxa_insucesso_fornecedor\",\"complexidade_obra\",\"risco_etapa\"\n",
        "]].head())"
      ],
      "metadata": {
        "id": "mNYsCfuc6Sqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 6. Prepara√ß√£o Final das Features\n",
        "# ============================================================\n",
        "df_model = pd.get_dummies(\n",
        "    df_mestre[[\n",
        "        \"orcamento_estimado\",\n",
        "        \"rating_confiabilidade\",\n",
        "        \"material\",\n",
        "        \"cidade\",\n",
        "        \"etapa\",\n",
        "        \"taxa_insucesso_fornecedor\",\n",
        "        \"complexidade_obra\",\n",
        "        \"risco_etapa\",\n",
        "        \"dias_atraso\"\n",
        "    ]],\n",
        "    columns=[\"material\", \"cidade\", \"etapa\"]\n",
        ")\n",
        "\n",
        "X = df_model.drop(\"dias_atraso\", axis=1)\n",
        "y = df_model[\"dias_atraso\"]\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"X:\", X.shape, \"| y:\", y.shape)"
      ],
      "metadata": {
        "id": "uXw1NaWl6ZxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 7. Divis√£o Treino/Teste e Treinamento\n",
        "# ============================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Modelo treinado.\")"
      ],
      "metadata": {
        "id": "56eSo7F46gsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 8. Avalia√ß√£o do Modelo\n",
        "# ============================================================\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== Avalia√ß√£o do Modelo ===\")\n",
        "print(f\"Erro M√©dio Absoluto (MAE): {mae:.2f} dias\")\n",
        "print(f\"R¬≤ Score: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "QxLkgwDV6mrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 9. Interpreta√ß√£o Visual das Features\n",
        "# ============================================================\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    \"Feature\": X.columns[indices],\n",
        "    \"Import√¢ncia\": importances[indices]\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=\"Import√¢ncia\", y=\"Feature\", data=feature_importance_df, palette=\"viridis\")\n",
        "plt.title(\"Import√¢ncia das Features no Modelo RandomForest\", fontsize=14)\n",
        "plt.xlabel(\"Import√¢ncia relativa\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Top 10 Features mais importantes:\")\n",
        "print(feature_importance_df.head(10))"
      ],
      "metadata": {
        "id": "fvM3wYa_6uNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 10. Impacto de Neg√≥cio\n",
        "# ============================================================\n",
        "custo_por_dia = 50000\n",
        "impacto_financeiro = mae * custo_por_dia\n",
        "\n",
        "print(\"=== Impacto de Neg√≥cio ===\")\n",
        "print(f\"Cada dia de atraso custa aproximadamente R$ {custo_por_dia:,.0f}.\")\n",
        "print(f\"Com um erro m√©dio de {mae:.2f} dias, o impacto financeiro potencial √© de ~R$ {impacto_financeiro:,.0f}.\")"
      ],
      "metadata": {
        "id": "E5Gu0ulx60pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 11. Salvar Modelo\n",
        "# ============================================================\n",
        "import os\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "joblib.dump(model, \"models/modelo_random_forest.pkl\")\n",
        "print(\"Modelo salvo em models/modelo_random_forest.pkl\")"
      ],
      "metadata": {
        "id": "_xalNeM667Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Previs√£o de Atrasos ‚Äì Vers√£o Executiva\n",
        "\n",
        "## üéØ Objetivo\n",
        "Antecipar atrasos em etapas de obras, permitindo a√ß√µes preventivas que reduzem custos e riscos.\n",
        "\n",
        "## üîë Principais Resultados\n",
        "- **Erro M√©dio Absoluto (MAE):** ~X dias\n",
        "- **R¬≤ Score:** ~Y\n",
        "- **Impacto Financeiro M√©dio:** ~R$ Z por obra (considerando R$ 50.000/dia)\n",
        "\n",
        "## üß© Vari√°veis mais relevantes\n",
        "- Risco da Etapa\n",
        "- Taxa de Insucesso do Fornecedor\n",
        "- Complexidade da Obra\n",
        "- Localiza√ß√£o e Materiais\n",
        "\n",
        "## üí° Insights Estrat√©gicos\n",
        "- Antecipar atrasos para negociar prazos e replanejar cronogramas.\n",
        "- Reduz multas e custos indiretos.\n",
        "- Melhora confiabilidade da entrega e satisfa√ß√£o dos clientes.\n",
        "\n",
        "## üöÄ Conclus√£o\n",
        "Este modelo conecta ci√™ncia de dados ao valor financeiro. Com previs√µes de atrasos,\n",
        "gestores podem agir com anteced√™ncia, economizando e fortalecendo a competitividade."
      ],
      "metadata": {
        "id": "6HgF8Qh77Ebp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# 12. Simulador de Risco ‚Äì Exemplo de uso do modelo\n",
        "# ============================================================\n",
        "\n",
        "# Exemplo de como usar o modelo para uma nova obra\n",
        "nova_obra = {\n",
        "    'orcamento_estimado': 12000000,\n",
        "    'rating_confiabilidade': 2.5,\n",
        "    'taxa_insucesso_fornecedor': 0.8,  # fornecedor perigoso\n",
        "    'complexidade_obra': np.log1p(12000000),\n",
        "    'risco_etapa': 10.0,\n",
        "    'material': 'concreto',\n",
        "    'cidade': 'Belo Horizonte',\n",
        "    'etapa': 'Funda√ß√£o'\n",
        "}\n",
        "\n",
        "# Transformar em DataFrame para prever\n",
        "df_nova = pd.DataFrame([nova_obra])\n",
        "\n",
        "# Aplicar one-hot encoding igual ao treinamento\n",
        "df_nova_encoded = pd.get_dummies(df_nova, columns=[\"material\",\"cidade\",\"etapa\"])\n",
        "\n",
        "# Garantir que tenha as mesmas colunas de X (adiciona colunas faltantes com 0)\n",
        "for col in X.columns:\n",
        "    if col not in df_nova_encoded.columns:\n",
        "        df_nova_encoded[col] = 0\n",
        "\n",
        "# Reordenar colunas\n",
        "df_nova_encoded = df_nova_encoded[X.columns]\n",
        "\n",
        "# Fazer previs√£o\n",
        "pred_atraso = model.predict(df_nova_encoded)[0]\n",
        "\n",
        "print(\"=== Simulador de Risco ===\")\n",
        "print(f\"Previs√£o de atraso para a nova obra: {pred_atraso:.2f} dias\")"
      ],
      "metadata": {
        "id": "p3kSFOzK_3uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# 1. Garantir que a pasta de destino existe\n",
        "path_figures = '../reports/figures'\n",
        "if not os.path.exists(path_figures):\n",
        "    os.makedirs(path_figures)\n",
        "\n",
        "# 2. Salvar o Gr√°fico de Import√¢ncia das Features\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=\"Import√¢ncia\", y=\"Feature\", data=feature_importance_df, palette=\"viridis\")\n",
        "plt.title(\"Import√¢ncia das Features no Modelo RandomForest\", fontsize=14)\n",
        "plt.xlabel(\"Import√¢ncia relativa\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Salvando a imagem\n",
        "plt.savefig(f'{path_figures}/feature_importance.png', dpi=300)\n",
        "print(f\"‚úÖ Gr√°fico salvo em: {path_figures}/feature_importance.png\")\n",
        "\n",
        "# 3. Gerar Texto para o README (M√©tricas)\n",
        "print(\"\\n--- COPIE E COLE NO SEU README.MD ---\")\n",
        "markdown_metrics = f\"\"\"\n",
        "| M√©trica | Valor |\n",
        "| :--- | :--- |\n",
        "| **Erro M√©dio Absoluto (MAE)** | {mae:.2f} dias |\n",
        "| **R¬≤ Score** | {r2:.2f} |\n",
        "| **Impacto Financeiro (R$)** | R$ {impacto_financeiro:,.2f} |\n",
        "\"\"\"\n",
        "print(markdown_metrics)"
      ],
      "metadata": {
        "id": "C8WGavZtPB7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# 1. Garantir que a pasta de destino existe\n",
        "path_figures = '../reports/figures'\n",
        "if not os.path.exists(path_figures):\n",
        "    os.makedirs(path_figures)\n",
        "\n",
        "# 2. Salvar o Gr√°fico de Import√¢ncia das Features\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=\"Import√¢ncia\", y=\"Feature\", data=feature_importance_df, palette=\"viridis\")\n",
        "plt.title(\"Import√¢ncia das Features no Modelo RandomForest\", fontsize=14)\n",
        "plt.xlabel(\"Import√¢ncia relativa\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Salvando a imagem\n",
        "plt.savefig(f'{path_figures}/feature_importance.png', dpi=300)\n",
        "print(f\"‚úÖ Gr√°fico salvo em: {path_figures}/feature_importance.png\")\n",
        "\n",
        "# 3. Gerar Texto para o README (M√©tricas)\n",
        "print(\"\\n--- COPIE E COLE NO SEU README.MD ---\")\n",
        "markdown_metrics = f\"\"\"\n",
        "| M√©trica | Valor |\n",
        "| :--- | :--- |\n",
        "| **Erro M√©dio Absoluto (MAE)** | {mae:.2f} dias |\n",
        "| **R¬≤ Score** | {r2:.2f} |\n",
        "| **Impacto Financeiro (R$)** | R$ {impacto_financeiro:,.2f} |\n",
        "\"\"\"\n",
        "print(markdown_metrics)"
      ],
      "metadata": {
        "id": "GPV4iUJrPyNN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}